
\documentclass[preprint,nocopyrightspace]{sigplanconf}

\input{preamble}

\title{A Simple Finite Volume Method Discretization of the
  Magnetostatic Potential Problem}

\authorinfo{Kenny Erleben} {Department of Computer Science\\University of
  Copenhagen} {kenny@diku.dk}

\date{ August 2014 }

\hypersetup{
colorlinks,%
citecolor=black,%
filecolor=black,%
linkcolor=black,%
urlcolor=black,%
bookmarksopen=false,%
pdftitle={Fast LCP solver for Solid Wall Boundary Conditions in Incompressible Fluids},%
pdfauthor={Kenny Erleben and Michael Andersen}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract} 
Here I outline how to get the second order boundary condition
$\frac{\partial^2 \phi}{\partial n^2} = 0$ into a simple finite volume
method discretization.

\keywords{Magnetostatic Potentialss, Boundary Conditions}
\category{I.3.5}{Computer Graphics}{Computational Geometry and Object Modeling}[Physically based modeling]
\category{G.1.0}{Mathematics of Computing}{General}[Numerical Algorithms]
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{The Mathematical Model of Magnetostatic Problems}
\label{sec:model}
Omitting the physics details for brevity we simply state the
mathematical model here as a partial differential equation (PDE)
problem. We are solving for the unknown potential field $\phi : \Re^2
\mapsto \Re$ given the govering equation
\begin{equation}
  \nabla^2 \phi(\vec x) = \nabla \cdot \vec m(\vec x)
\end{equation}
where $\nabla = ( \frac{\partial }{\partial x}, \frac{\partial
}{\partial y})^T$ is the differential vector operator and the position
field is given by $\vec x = (x,y) \in \Re^2$. Here $\vec m(\vec x)$ is
a known dipole field assumed constant inside and on the surface of the
magnet and zero out-side the magnet. Let the magnet be given by the
closed point set $\set
A \equiv \left\{ \vec x \in \Re^2 \, |\, \vec x \in \text{magnet}
\right\}$ then we may write
\begin{equation}
  \vec m(\vec x) =
  \begin{cases}
    \vec k & \text{if $\vec x \in \set A$}, \\
    \vec 0 & \text{if $\vec x \notin \set A$}
  \end{cases}
\end{equation}
where $\vec k$ is a user-specified constant. typically $\vec k =
(1,0)^T$.

To make the model well-posed we need one Dirichlet condition at a
single point in our domain.
\begin{equation}
  \phi(\vec x_{\text{DC}}) = 0
\end{equation}
where $\vec x_{\text{DC}}$ is some known location in our domain.  We
assume our domain given by the point set $\Omega$ is a square
domain. Hence we typically apply the Dirichlet condition at the
lower-left corner point of the domain.

On our domain boundaries we need to specify the behaviour of
$\phi(\vec x)$ to make our model well-posed.  Given that we wish to
model an infinite big world we wish for the potential field to
expand/extrapolate across boundaries unchanged. This implies that the
slope of $\phi(\vec x)$ across the boundaries should be unchanged. Let
the boundaries be given by the point set $\Gamma$ then we can now
write the desired boundary conditions as follows
\begin{equation}
  \frac{\partial^2  \phi(\vec x) }{\partial^2 \vec n} = 0 \quad \forall
  \vec x \in \Gamma
\end{equation}
where $\vec n$ is the outward unit normal at the boundary point.

\section{Discretization using a Triangle Mesh}
\label{sec:discretization}
To numerically solve for $\phi$ we discretize the model on a triangle
mesh using the finite volume method. Our mesh layout uses the
triangles as control volumes and stores a single $\phi$ value et the
geometric center of each triangle. We assume that the boundary of the
magnet to be conforming with the edges of our triangles. Hence a
triangle is either completely inside the magnet or totally outside the
magnet. As the magnet is considered a closed point set, we consider
the edge between a air-triangle and magnet-triangle to be a
magnet-edge.

Let us consider the $C\th$ triangle with the counter-clock-wise vertex
labels $i$, $j$, and $k$. Let the adjacent triangles be labeled by
$I$, $J$, and $K$ in such a way that triangle $I$ is opposite vertex
$i$. That is triangle $I$ is sharing edge $jk$ with triangle $C$.  Let
$\set V \equiv \{i, j, k\}$ and $\set N \equiv\{ I, J, K\}$. We denote
the geometric centers of the four triangles as $\vec x_C$, $\vec x_I$,
$\vec x_J$, and $\vec x_K$, similar vertex positions are $\vec x_i$,
$\vec x_j$, and $\vec x_k$. The vector between two positions are
written as $\vec l_{ik} = \vec x_i - \vec x_k$ and the length between
two positions are $l_{ik} = \norm{ \vec x_i-\vec x_k}$, similar $\vec
l_{ij}$ and $l_{ij}$ would have the same semantics.


To derive the finite volume method we first write the partial
differential equation into volume form
\begin{equation}
  \int_{\Omega_c} \nabla \cdot \nabla \phi(\vec x) dA 
  = 
  \int_{\Omega_c} \nabla \cdot \vec m(\vec x) dA
\end{equation}
where $\Omega_c$ is the closed point-set of the $C\th$ triangle and
$dA$ is the differential area element. Next we apply the Gauss
divergence theorem
\begin{equation}
  \oint_{\Gamma_c} \vec n \cdot \nabla \phi(\vec x) dS
  = 
  \oint_{ \Gamma_c} \vec n \cdot \vec m(\vec x) dS
\end{equation}
and $dS$ is the differential arc-length element. Since the triangle
has three edges of constant outward unit normals we use this knowledge
to rewrite into
\begin{equation}
  \begin{split}
  &\int_{\Gamma_I} \vec n_I \cdot \nabla \phi dS
  +
  \int_{\Gamma_J} \vec n_J \cdot \nabla \phi dS
  +
  \int_{\Gamma_K} \vec n_K \cdot \nabla \phi dS\\
  &= 
  \int_{\Gamma_I} \vec n_I \cdot \vec m  dS
  +
  \int_{\Gamma_J} \vec n_J \cdot \vec m  dS
  +
  \int_{\Gamma_K} \vec n_K \cdot \vec m dS    
  \end{split}
\end{equation}
Here $\vec n_I$ is the outward unit normal of the edge between
triangle $C$ and triangle $I$. Hence it is given by
\begin{equation}
  \vec n_I =  - \frac{  \hat{ \vec l }_{kj}  }{  l_{kj}  }
\end{equation}
Next we apply the mid-point rule approximation that is
\begin{equation}
  \begin{split}
    &\vec n_I \cdot \nabla \phi(\vec e_I) l_{kj}
    +
    \vec n_J \cdot \nabla \phi(\vec e_J) l_{ik}
    +
    \vec n_K \cdot \nabla \phi(\vec e_K) l_{ji}\\
    &=
    \vec n_I \cdot \vec m(\vec e_I)  l_{kj} 
    + \vec n_J \cdot \vec m(\vec e_J)  l_{ik} 
    + \vec n_K \cdot \vec m(\vec e_K)  l_{ji} 
  \end{split}
\end{equation}
where $\vec e_I$ means the midpoint of edge $I$. That is $\vec e_I =
\frac{\vec x_k + \vec x_j}{2}$. Now the problem is that there do not exist
a $\phi$-value at the $\vec e$'s.. However, we may approximate the directional derivative at $\vec
e_I$ in the direction of $\vec n_I$ by a Taylor approximation (see
Appendix~\ref{sec:appr-direct-deriv} for details),
\begin{equation}
  \vec n_I \cdot \nabla \phi(\vec e_I) \approx \frac{  \phi_I - \phi_C  }{ l_{CI}} 
\end{equation}
So we finally have the numerical stencil
\begin{equation}
  \underbrace{\sum_{I \in \set N}  l_{kj} \frac{  \phi_I - \phi_C  }{
      l_{CI}}}_{
\equiv
\mat A_{CC} \phi_C + \mat A_{CI} \phi_I + \mat A_{CJ} \phi_J + \mat
A_{CK} \phi_K 
}
  =
\underbrace{
  \sum_{I \in \set N}  l_{kj} \vec n_I \cdot \vec m(\vec e_I)
}_{\equiv \vec b_C}
\end{equation}
That is the numerical stencil results in a four banded symmetric
positive semi definite matrix given by the $A$-terms below
\begin{equation}
  \label{eq:final:stencil}
  \mat A_{CC} \phi_C + \mat A_{CI} \phi_I + \mat A_{CJ} \phi_J + \mat A_{CK} \phi_K
  =  
  \vec b_C
\end{equation}
where
\begin{subequations}
\begin{align}
  \mat A_{CC} &= - \frac{ l_{kj} }{ l_{CI}} - \frac{ l_{ik} }{
    l_{CJ}} - \frac{  l_{ji} }{ l_{CK}}, \\
  \mat A_{CI} &=  \frac{  l_{kj} }{ l_{CI}},\\
  \mat A_{CJ} &= \frac{ l_{ik} }{ l_{CJ}}, \\
  \mat A_{CK} &=  \frac{  l_{ji} }{ l_{CK}}. 
\end{align}  
\end{subequations}
We omit further details on the right hand side vector $\vec b_c$ as it
is trivial to evaluate given the closed-form solution of a given known
constant $\vec m$-field.  Defining triangle boundaries to coincide
perfectly with the magnet boundary is the unique trait that allow us
to treat $\vec b_C$ in this simple fashion.  What we are missing now
is how to deal with the higher order Neumann boundary conditions. This
takes a little more work.


\subsection{Higher Order Neumann Condition}
\label{sec:higher-order-neumann}
We will now address the case of having a triangle $C$ with one open
boundary edge. We assume without loss of generality that the boundary
edge is $I$. On this edge we must apply the second order Neumann
condition. From \eqref{eq:final:stencil} we immediately notice a
problem as the numerical stencil is referencing the value $\phi_I$ and
that value does actually not exist in the mesh. To circumvent this we
imagine a ghost triangle (cell) being placed across the
boundary. Hence $\phi_I$ are the imaginary value stored in this ghost
cell.


We will now derive the closed-form solution of the discrete ghost
value $\phi_I$. We extrapolate this value under the assumption that
the gradient $\nabla \phi$ remains unchained across the solid
boundary. This assumption is equivalent to the second order Neumann
condition we wish to apply on that boundary.

We first recover the value of $\nabla \phi$ at cell $C$ using the
known directional gradient derivatives
\begin{align}
\vec n_J^T \nabla \phi &= \frac{\phi_J - \phi_C}{l_{JC}} \label{eq:dir_deriv_j}\\
\vec n_K^T \nabla \phi &= \frac{\phi_K - \phi_C}{l_{KC}} \label{eq:dir_deriv_k}
\end{align}
and then use it to compute the value of $\phi_I$ from
\begin{align}
\vec n_I^T \nabla \phi &= \frac{\phi_I - \phi_C}{l_{IC}}. \label{eq:dir_deriv_i}
\end{align}
The two expressions for directional derivatives
\eqref{eq:dir_deriv_j}--\eqref{eq:dir_deriv_k} form a system of two
linear equations with two unknowns (the two coordinates of $\nabla
\phi$). By rewriting them in scalar form, we obtain
\begin{align}
n_J^x \nabla \phi^x + n_J^y \nabla \phi^y =& \frac{\phi_J-\phi_C}{l_{JC}} \label{eq:dir_deriv_J_scalar}\\
n_K^x \nabla \phi^x + n_K^y \nabla \phi^y =& \frac{\phi_K-\phi_C}{l_{KC}}. \label{eq:dir_deriv_K_scalar}
\end{align}
By multiplying Eq. \eqref{eq:dir_deriv_J_scalar} by $n_K^y$ and
Eq. \eqref{eq:dir_deriv_K_scalar} by $n_J^y$, and then subtracting
\eqref{eq:dir_deriv_K_scalar} from \eqref{eq:dir_deriv_J_scalar} we
eliminate $\nabla \phi^y$ from the system and find
\begin{equation}
  \begin{split}
    \left(n_J^x n_K^y - n_J^y n_K^x \right) \nabla \phi^x &=
    \left(\frac{\phi_J-\phi_C}{l_{JC}} \right)n_K^y 
    \\
    &- 
    \left(\frac{\phi_K-\phi_C}{l_{KC}} \right) n_J^y. 
  \end{split}
\end{equation}
Let us stop and look at the coefficient at $\nabla \phi^x$. By
definition of the cross product between $\vec n_J$ and
$\vec n_K$ we obtain
\begin{equation}
  \begin{split}
    n_J^x n_K^y - n_J^y n_K^x &= \vec n_J \times \vec n_K = \vec n_K^T\hat{\vec n }_J,
  \end{split}
\end{equation}
Clearly if the triangle is non-degenerate cross products of normal
will be non-zero as any two normal vectors never will be parallel
vectors. Hence we can make a division and write
\begin{equation}
  \nabla \phi^x 
  =
  \frac{n_K^y}{ \vec n_K^T \hat{\vec n}_J} 
  \left(\frac{\phi_J-\phi_C}{l_{JC}} \right) 
  -
  \frac{n_J^y}{ \vec n_K^T \hat{\vec n}_J} 
  \left(\frac{\phi_K-\phi_C}{l_{KC}} \right) 
 .
\end{equation}
By analogy, we obtain
\begin{equation}
\nabla \phi^y 
=
-
  \frac{n_K^x}{ \vec n_K^T \hat{\vec n}_J} 
\left(\frac{\phi_J-\phi_C}{l_{JC}} \right)
 +
  \frac{n_J^x}{ \vec n_K^T \hat{\vec n}_J} 
\left(\frac{\phi_K-\phi_C}{l_{KC}} \right) .
\end{equation}
By putting these values together, we find that
\begin{equation}
  \nabla \phi 
  =
  \frac{\hat{\vec n}_J}{ \vec n_K^T \hat{\vec n}_J} 
  \left(\frac{\phi_K-\phi_C}{l_{KC}} \right) 
  -
  \frac{\hat{\vec n}_K}{ \vec n_K^T \hat{\vec n}_J} 
  \left(\frac{\phi_J-\phi_C}{l_{JC}} \right)
   .
\end{equation}
Now we can substitute this value into \eqref{eq:dir_deriv_i}
\begin{align}
  \frac{\phi_I - \phi_C}{l_{IC}} 
  &=
  \vec n_I^T \nabla \phi 
  \\
  {} 
  &
  =
  -
  \frac{\vec{n}_I^T \hat{\vec{n}}_K}{\vec{n}_K^T \hat{\vec{n}}_J}
  \left(\frac{\phi_J-\phi_C}{l_{JC}} \right)
  -
  \frac{\vec{n}_J^T \hat{\vec{n}}_I}{\vec{n}_K^T \hat{\vec{n}}_J}
  \left(\frac{\phi_K-\phi_C}{l_{KC}} \right).
\end{align} 
Therefore, the closed-form solution for
$\phi_I$ reads
\begin{equation}
  \label{eq:phi_i_closed_form}
  \begin{split}
    \phi_I &=
    \left(
      1 
      +
      \frac{
         \vec{n}_I^T \hat{\vec{n}}_K
       }{
         \vec{n}_K^T\hat{\vec{n}}_J
       } 
      \frac{
         l_{IC}
       }{
         l_{JC}
       } 
      +
      \frac{
        \vec{n}_J^T \hat{\vec{n}}_I
      }{
        \vec{n}_K^T\hat{\vec{n}}_J
      } 
      \frac{
        l_{IC}
      }{
        l_{KC}
      } 
    \right)\phi_C
    \\
    &-
      \frac{
         \vec{n}_I^T \hat{\vec{n}}_K
       }{
         \vec{n}_K^T\hat{\vec{n}}_J
       } 
      \frac{
         l_{IC}
       }{
         l_{JC}
       } 
    \phi_J
    \\
    & -
      \frac{
        \vec{n}_J^T \hat{\vec{n}}_I
      }{
        \vec{n}_K^T\hat{\vec{n}}_J
      } 
      \frac{
        l_{IC}
      }{
        l_{KC}
      } 
      \phi_K.    
  \end{split}
\end{equation}
\kenny{Observe that $l_{IC}$ is actually not known as $\vec x_I$ does not
  exist. For now in our derivation we simply use the edge midpoint
  $\vec x_I$ to define $l_{IC}$. Later we will observe that the
  $l_{IC}$ terms cancel out. }
An alternative route leading to the same solution is by expressing
$\mathbf{n}_I$ as a linear combination of $\mathbf{n}_J$ and
$\mathbf{n}_K$:
\begin{equation}
\vec{n}_I = a \,\vec{n}_J + b\, \vec{n}_K.\label{eq:lin_comb_n}
\end{equation}
We find $a$ by transposing the last equation and multiplying both
sides by $\hat{\vec{n}}_K$ (orthogonal to $\vec{n}_K$)
\begin{equation}
\vec{n}_I^T \hat{\vec{n}}_K = a \,\vec{n}_J^T \hat{\vec{n}}_K + b\, \vec{n}_K^T \hat{\vec{n}}_K = a \,\vec{n}_J^T \hat{\vec{n}}_K,
\end{equation}
hence
\begin{equation}
a
 =
 \frac{\vec{n}_I^T \hat{\vec{n}}_K}{\vec{n}_J^T
   \hat{\vec{n}}_K} 
=
 -\frac{\vec{n}_I^T \hat{\vec{n}}_K}{\vec{n}_K^T \hat{\vec{n}}_J}.
\end{equation}
Now by transposing \eqref{eq:lin_comb_n} and multiplying onto
$\hat{\mathbf{n}}_J$ we find
\begin{equation}
  b 
  =
  \frac{\vec{n}_I^T \hat{\vec{n}}_J}{\vec{n}_K^T \hat{\vec{n}}_J}
  =
  -\frac{\vec{n}_J^T \hat{\vec{n}}_I}{\vec{n}_K^T \hat{\vec{n}}_J}
  .
\end{equation}
Having found $a$ and $b$, we can substitute them into
\eqref{eq:dir_deriv_i}
\begin{equation}
\frac{\phi_I - \phi_C}{l_{IC}} = \vec{n}_I^T \nabla \phi = a \,\vec{n}_J^T \nabla \phi + b \,\vec{n}_K^T \nabla \phi
\end{equation}
Now substituting \eqref{eq:dir_deriv_j} and \eqref{eq:dir_deriv_k}
yields the exact same closed-form formula as the one in
\eqref{eq:phi_i_closed_form}. Note that both derivations hinge on the
assumption that the expressions for directional derivatives
\eqref{eq:dir_deriv_j}--\eqref{eq:dir_deriv_i} are accurate, i.e. when
all triangles in the mesh are nearly equilateral.

Having two open boundary edges is a degenerate case. However we can
resolve this easily in the moving mesh framework by applying an
edge-split on the inner edge on all triangles having two boundary
edges. Hence we can safely assume that a triangle cell can have at
most one boundary edge.

\subsection{An Implementation Friendly Version}
\label{sec:implementation}
Let us now derive a generic implementation friendly equation. First we
introduce the auxiliary notation for \eqref{eq:phi_i_closed_form} as
follows
\begin{equation}
  \label{eq:boundary:coefficients:I}
  \phi_I = B_{IC} \phi_C +B_{IJ} \phi_J +B_{IK} \phi_K
\end{equation}
We refer to the $B$-values as the boundary coefficients. In case $J$
or $K$ where boundary edges we would find
\begin{subequations}
\begin{align}
  \phi_J &= B_{JC} \phi_C +B_{JI} \phi_I +B_{JK} \phi_K,   \label{eq:boundary:coefficients:J}\\
  \phi_K &= B_{KC} \phi_C +B_{KJ} \phi_J +B_{KI} \phi_I
  \label{eq:boundary:coefficients:K}
\end{align}  
\end{subequations}
Given that edge $I$ is a boundary edge one must substitute
\eqref{eq:boundary:coefficients:I} into \eqref{eq:final:stencil} to
obtain the final modified stencil that takes the boundary conditions
into account. The result is
\begin{equation}
  \label{eq:final:stencil:modified}
  \mat A^\prime_{CC}\, \phi_C + \mat A^\prime_{CI} \,\phi_I + \mat A^\prime_{CJ}\, \phi_J + \mat A^\prime_{CK} \,\phi_K
  =  
  \vec b_C
\end{equation}
where
\begin{subequations}
  \begin{align}
    \mat A^\prime_{CC} &= \mat A_{CC}  + \mat A_{CI} \, B_{IC}, \\
    \mat A^\prime_{CI} &= 0, \\
    \mat A^\prime_{CJ} &= \mat A_{CJ}  + \mat A_{CI} \,  B_{IJ}, \\
    \mat A^\prime_{CK} &= \mat A_{CK}  + \mat A_{CI} \,  B_{IK}.
  \end{align}  
\end{subequations}
\kenny{Recall our previous comment about $l_{IC}$ terms cancel
  out. Observe above that the $\mat B$-terms and $l_{IC}$ in
  numerators whereas the $\mat A$-terms have $l_{IC}$-terms in
  denominators. Hence multiplication of $\mat A$ and $\mat B$ terms
  will cancel out $l_{IC}$-terms. Therefore the actual value of
  $l_{IC}$ is of lesser importance.} Now let us generalize the concept
and define the $C$ modification coefficients as follows
\begin{equation}
  \label{eq:modification:}
  C_{AB} =
  \begin{cases}
    -1 & \text{if $A=B$ and $A$ is on boundary} \\
    B_{AB} & \text{if $A$ is on boundary} \\
    0 & \text{otherwise} 
\end{cases}
\end{equation}
where $A \in \{I,J,K\}$ and $B \in \{I,J,K,C\}$. Now all cases can be handled using
\begin{subequations}
  \begin{align}
    \mat A^\prime_{CC} &= \mat A_{CC}  + \mat A_{CI} \,  C_{IC}+ \mat A_{CJ} \,  C_{JC}+ \mat A_{CK} \,  C_{KC}, \\
    \mat A^\prime_{CI} &= \mat A_{CI}  + \mat A_{CI} \,  C_{II} + \mat A_{CJ} \,  C_{JI}+ \mat A_{CK} \,  C_{KI}, \\
    \mat A^\prime_{CJ} &= \mat A_{CJ}  + \mat A_{CI} \,  C_{IJ} + \mat A_{CJ} \,  C_{JJ}+ \mat A_{CK} \,  C_{KJ}, \\
    \mat A^\prime_{CK} &= \mat A_{CK}  + \mat A_{CI} \,  C_{IK} + \mat A_{CJ} \,  C_{JK} + \mat A_{CK} \,  C_{KK}.
  \end{align}  
\end{subequations}
The benefit is that all cases are encoded into the $C$-definition
which can be implemented using question-mark statements. Hence by
paying for 12 additional temporary local variables one can avoid
witting a lot of if-statements causing thread divergence. This is an
advantage as the matrix assembly is data parallel and the above
computations can be done naively parallel. Even in the case of matrix
free methods one can make a massively parallel operator for evaluating
the matrix-vector product $\mat A \, \vec \phi$ without any thread
divergence. Of course using locals could have the side-effect of
register usage becoming the limiting resource bottleneck on certain
GPUs.


\kenny{Obviously the magneto static potential problem with 1st order
  Neumann conditions will be symmetric. Clearly the fill-in for the
  2nd order Neumann condition will be symmetric too (same memory
  layout), however the values stored in the modified system are no
  longer symmetric. (Can we prove this formally?)}

\appendix

\section{The Approximation of Directional Derivative}
\label{sec:appr-direct-deriv}
Let us revisit the approximation
\begin{equation}
  \vec n_I \cdot \nabla \phi(\vec e_I) \approx \frac{  \phi_I - \phi_C  }{ l_{CI}}.
\end{equation}
We assume that the geometry of the mesh is such that
\begin{subequations}
\begin{align}
  \vec x_I &=  \vec e_I  + \vec n_I \, l_{CI}\left(1-\gamma\right),\\
  \vec x_C &=  \vec e_I - \vec n_I \, l_{CI}  \, \gamma,
\end{align}  
\end{subequations}
where $0 < \gamma < 1$ is some known constant. Now we use Taylor series approximations around
$\phi(\vec e_I)$
\begin{subequations}
\begin{align}
  \phi(\vec x_I) &=  \phi(\vec e_I)  +  \nabla \phi(\vec e_I) \cdot
  \vec n_I \, l_{CI} \left(1-\gamma\right) + \bigO\left(  l_{CI}^2 \right), \\
  \phi(\vec x_C) &=  \phi(\vec e_I)  -  \nabla \phi(\vec e_I) \cdot
  \vec n_I \, l_{CI}  \, \gamma + \bigO\left(  l_{CI}^2 \right).
\end{align}  
\end{subequations}
Subtracting the two approximations we have
\begin{equation}
  \phi(\vec x_I) -  \phi(\vec x_C) =   \nabla \phi(\vec e_I) \cdot
  \vec n_I \, l_{CI} + \bigO\left(  l_{CI}^2 \right).
\end{equation}
Cleaning up we find
\begin{equation}
  \nabla \phi(\vec e_I) \cdot \vec n_I 
  =
  \frac{
    \phi(\vec x_I) -  \phi(\vec x_C)
  }{l_{CI}} + \bigO\left(  l_{CI} \right). 
\end{equation}
Hence we find the first-order approximation of the directional
derivative to be
\begin{equation}
  \nabla \phi(\vec e_I) \cdot \vec n_I 
  \approx
  \frac{
    \phi(\vec x_I) -  \phi(\vec x_C)
  }{l_{CI}} .
\end{equation}
Besides our discretization error we are making the assumptions that
the line connecting $\vec x_I$ and $\vec x_C$ goes orthogonal through
the edge mid-point $\vec e_I$. This requires a very special mesh with
only equilateral triangles. Real-life meshes do not have this property
all over. Hence we are making some errors too due to our geometry
assumptions.

If we assume the size of the elements is sufficiently small that we
can assume a linear approximation over the elements then a reasonable
measure of the error we make by assuming the line between the cell
centers are orthogonal can be defined as
\begin{equation}
  \varepsilon_I 
  \equiv 
  \sin
  \left( 
    \theta_I 
  \right) 
  =
  \vec n_I 
  \cdot
  \frac{
    \vec l_{IC}
  }{
    l_{IC}
  }
\end{equation}

\section{Mesh Control}\label{sec:mesh-control}
The error measure $\varepsilon_I$ can be used for mesh control in such
a way to make $\varepsilon_I \rightarrow 0$. Another way to control
the mesh is such that the assumption that $\phi$ behaves sufficiently
linear on the triangle $C$. One way to measure if this property is
fulfilled is to make a linear model based on a small patch of $\phi$
samples and then measure how well $\phi_C$ fits with this model. For
an arbitrary triangle let $\set V_T$ denote its vertex set. hence
$\set V_C$ is $\{i, j, k\}$ and let $\text{label}\left(T\right)$ be a
mapping of triangles to whether they belong to the magnetic or
non-magnetic region of the computational domain. Now we can define the
one ring restricted neighbourhood patch of $C$ to be
\begin{equation}
  \set P_c 
  \equiv
  \left\{  
    n 
    \, | \, 
    \set V_n \intersection \set V_c  \neq \emptyset
    \, \logand \, 
    \text{label}(n) = \text{label}(c)
  \right\}
\end{equation}

Define the coefficient vector as $\vec c \equiv ( c_0, c_1, c_2  )^T$
then a linear model of the patch is computed using linear least
squares error
\begin{equation}
  \vec c^* 
  \equiv 
  \arg \min_{\vec c} 
\underbrace{
  \frac{1}{2}  
  \sum_{T \in \set P_C}
  \left(       
c_0 + c_1 \, x_T + c_2 \, y_T
- \phi_T
  \right)^2
}_{f(\vec c)}
\end{equation}
Knowing $\vec c^*$ we have a linear ``best'' model of the patch
\begin{equation}
  L(x,y;\vec c^*) \equiv c_0^*  + c_1^* x + c_2^* y
\end{equation}
From which we may estimate the sufficiently small assumption as
\begin{equation}
  \epsilon_C  = \left( L(x_C,y_C;\vec c^*) - \phi_C \right)^2 A_c
\end{equation}
Here we use the square error to get positive measures and we weight by
area to penalize too large regions. This is a somewhat heuristic based
measure found through trial and error but in our experience mesh
quality seems to behave nice with this measure of
quality. Alternatively one may simply use the value of $f(\vec c^*)$
as the error measure. This is by design non-negative and bounded from
below by zero. The objective function includes the ``area'' too as all
samples of the patch region contributes to the error measure.


To solve for the first order optimal coefficients $\vec c^*$ we need
to find a formula for the gradient of the objective function which we
derive from calculus to be
\begin{equation}
  \nabla f 
  \equiv
  \sum_{T \in \set P_C}
  L(  x_T, y_T, \vec c )
  \begin{bmatrix}
    1 \\
    x_T \\
    y_T
  \end{bmatrix}
\end{equation}
Without loss of generality assume indices of $\set P_C$ to be
$\{1,2,\ldots, T\}$ then we may introduce the matrix and vector
\begin{equation}
  \mat B =
  \begin{bmatrix}
    1 & x_1 & y_1 \\
    1 & x_2 & y_2 \\
    & \vdots & \\
    1 & x_T & y_T
  \end{bmatrix}
\quad\text{and}\quad
\vec \Phi
=
\begin{bmatrix}
  \phi_1 \\
  \phi_2 \\
  \vdots\\
  \phi_T 
\end{bmatrix}.
\end{equation}
We may now write the objective gradient using this new notation as
\begin{equation}
  \nabla f = \mat B^T \mat B \vec c + \mat B^T \vec \Phi 
\end{equation}
Solving for $\nabla f = \vec 0$ is now done solving the 3-by-3 system
\begin{equation}
  \left( \mat B^T \mat B \right) \vec c =  -  \mat B^T \vec \Phi 
\end{equation}
To be numerically well posed this requires the patch to have at least three elements, $\norm{\set
  P_C} \geq 3$. If this is the case then $\left( \mat B^T \mat B
\right)$ is guaranteed to be symmetric positive definite matrix and
hence non-singular. If less than three elements the matrix will be
positive semi-definite and hence singular. In other words the patch is
too small for the linear model to make sense the most sensible
solution would be to grow the patch region or add some other
assumptions for this specific case. Note that a patch with exactly
three elements will always yield a perfect fit to a linear
model. Hence it makes sense to require that a patch has at least 4 (or more)
elements to be able to test how well a linear model fits with the $\phi$-field.

\section{Jumping Gradients}
\label{sec:jumping-gradients}
One should observe that $\nabla \phi$ is non-smooth across magnet and
void boundaries hence our normal derivative approximation across those
edges are strictly speaking not valid in classical sense. If we apply
non-smooth theory and replace directional derivatives with
B-differentials then everything holds. Alternatively we could use our
open boundary approach on those edges to force a one-sided boundary
condition on the gradient from magnet region and void region
respectively. However, we would need to add a Dirichlet condition as
well to ensure that the $\phi$-field stays continuous and do not jump
across the magnet and void boundaries. We decided to go with the
non-smooth analysis argumentation although this could potentially add
some smoothness to the solution on the magnet-void
boundaries. However, on those boundaries we do control the mesh
element size to become very small hence the error we make can be made
as sufficiently small as we desire.



% \section{General Recipe for Boundaries}
% \label{sec:gener-recipe-bound}
% Let us just recap the practical issue of the mesh boundary before
% deriving different approaches to dealing with the boundary
% conditions. From discretization of triangle $C$ we have
% \begin{equation}
%   \label{eq:triangle:c:discretization}
%   \mat A_{CI} \phi_I
% +  \mat A_{CJ} \phi_J
% +  \mat A_{CK} \phi_K
% +  \mat A_{CC} \phi_C
% =
%   \vec b_{C}
% \end{equation}
% Imagine now that the edge $jk$ is a boundary edge that means that the
% value $\phi_I$ does not exist in the computational mesh. In principle
% we could have two boundary edges implying that for instance both
% $\phi_I$ and say $\phi_J$ does not exist.

% The recipe for dealing with this is to discretize a boundary condition like
% \begin{equation}
%   \frac{\partial^2 \phi}{\partial \vec n^2} = 0
% \end{equation}
% From the discretization process an update stencil is derived such as 
% \begin{equation}
%   \label{eq:boundary:edge:I:discretization}
%   \phi_I = \mat B_{IJ} \phi_J + \mat B_{IK} \phi_K + \mat B_{IC}
%   \phi_C + \vec c_I
% \end{equation}
% Substituting this into \eqref{eq:triangle:c:discretization} yields the
% modified triangle discretization
% \begin{equation}
%   \label{eq:triangle:c:modified:discretization}
%   \begin{split}
%   \left(\mat A_{CI} \mat B_{IJ}  +  \mat A_{CJ} \right)\phi_J
%   &+
%   \left(\mat A_{CI}\mat B_{IK} +  \mat A_{CK} \right)\phi_K \\
%   &+
%   \left(\mat A_{CI}\mat B_{IC} +  \mat A_{CC} \right)\phi_C \\
%   &=
% \left(  \vec b_{C} - \mat A_{CI}\vec c_I \right)    
%   \end{split}
% \end{equation}
% Introducing the modified coefficients
% \begin{align}
%   \label{eq:modified:coefficients}
%   \mat A_{CI}^\prime 
%   &=
%   \mat A_{CI} \mat B_{II} 
%   +
%   \mat A_{CJ} \mat B_{JI} 
%   +
%   \mat A_{CK} \mat B_{KI} 
%   +
%   \mat A_{CI}  
%   \\
%   \mat A_{CJ}^\prime 
%   &=  
%   \mat A_{CI} \mat B_{IJ} 
%   +
%   \mat A_{CJ} \mat B_{JJ} 
%   +
%   \mat A_{CK} \mat B_{KJ} 
%   +
%   \mat A_{CJ}  
%   \\
%   \mat A_{CK}^\prime 
%   &=
%   \mat A_{CI} \mat B_{IK} 
%   +
%   \mat A_{CJ} \mat B_{JK} 
%   +
%   \mat A_{CK} \mat B_{KK} 
%   +
%   \mat A_{CK}  
%   \\
%   \mat A_{CC}^\prime 
%   &=
%   \mat A_{CI} \mat B_{IC} 
%   +
%   \mat A_{CJ} \mat B_{JC} 
%   +
%   \mat A_{CK} \mat B_{KC} 
%   +
%   \mat A_{CC} 
%   \\
%   \vec b_{C}^\prime 
%   &=
%   \vec b_{C} 
%   -
%   \mat A_{CI} \vec c_{I} 
%   -
%   \mat A_{CJ} \vec c_{J} 
%   -
%   \mat A_{CK} \vec c_{K} 
% \end{align}
% Where the general rules apply
% \begin{align}
%   \mat B_{MN} &= 0  \quad \text{if  $M \notin \Gamma$}  \\
%   \mat B_{MN} &\neq 0  \quad  \text{if  $M \in \Gamma$ and $N \notin
%     \Gamma$}  \\
%   \mat B_{MM} &= -1  \quad \text{if  $M \in \Gamma$} 
% \end{align}
% This approach corresponds completely to assembling the matrix systems
% of the governing equations and boundary condition equations and
% performing a Shur complement. The advantage of this in-place
% substitution is a simpler in-place assembly process and that we by
% design make sure the fill-in pattern are unaffected. 

% \subsection{An algebraic Approach}
% \label{sec:an-algebr-appr}
% Assuming we are dealing with triangle $C$ and that edge $I \in
% \Gamma$.  Next we will present sufficient hand-waving based on the
% second order von Neumann boundary condition
% \begin{equation}
%   \frac{\partial^2 \phi}{\partial \vec n^2} = 0
% \end{equation}
% This condition suggest to us that the $\phi$ surface extents unchanged
% across edge $I$. That implies that in this small regional patch the
% gradient of $\phi$ across edge $I$ is unchanged. Hence given that
% elements are sufficiently small we may assuem the gradient to be
% constant in this region due to the second order von Neumann boundary
% condition.

% Now given that the elements in the mesh are sufficient small for the
% Taylor approximations to make sense then we can form the system of
% equations
% \begin{align}
%   \vec n_I^T \nabla \phi &= \frac{\phi_I - \phi_C}{l_{IC}} \\
%   \vec n_J^T \nabla \phi  &= \frac{\phi_J - \phi_C}{l_{JC}} \\
%   \vec n_K^T \nabla \phi &= \frac{\phi_K - \phi_C}{l_{KC}}
% \end{align}
% Putting into a matrix system and collecting the non-existing $\phi_I$
% and unknown gradient into one solution vector yields the linear system
% \begin{equation}
% \underbrace{
%   \begin{bmatrix}
%     l_{IC} \, \vec n_I^T & -1  \\
%     l_{JC} \, \vec n_J^T & 0\\
%     l_{KC} \, \vec n_K^T & 0
%   \end{bmatrix}
% }_{\mat C^{-1}}
%   \begin{bmatrix}
%     \nabla \phi\\
%     \phi_I
%   \end{bmatrix}
%   =
%   \begin{bmatrix}
%     -\phi_C \\
%     \phi_I -\phi_C \\
%     \phi_K  -\phi_C 
%   \end{bmatrix}
% \end{equation}
% Inverting $\mat C^{-1}$ the third row of the inverted system yields
% \begin{equation}
%   \phi_I = -\mat C_{31} \phi_C
%   + \mat C_{32} \left( \phi_J - \phi_C \right)
%   + \mat C_{33} \left( \phi_K - \phi_C \right)
% \end{equation}
% after cleaning up we have
% \begin{equation}
%   \phi_I 
%   =
%   \mat C_{32}  \phi_J
%   +
%   \mat C_{33} \phi_K
%   -
%   \left(
%     \mat C_{31}
%     +
%     \mat C_{32}
%     +
%     \mat C_{33}
%   \right) \phi_C
% \end{equation}
% From which we conclude that we have found
% \begin{align}
%   \mat B_{II} &= -1\\
%   \mat B_{IJ} &=  \mat C_{32}  \\
%   \mat B_{IK} &=  \mat C_{33} \\
%   \mat B_{IC} &=  - \left( \mat C_{31}+\mat C_{32}+\mat C_{33} \right) \\
%   \vec c_I &= 0 
% \end{align}
% Clearly if we extend the approach to two boundary edges $\mat C^{-1}$
% becomes under-constrained. The problem is essentially ill-posed as the
% gradient can not be found from only two $\phi$-values. Without loss of
% generality assume $I$ and $J$ to be boundary edges then one would
% obtain
% \begin{equation}
%   \mat C^{-1} =
%   \begin{bmatrix}
%     l_{IC} \, \vec n_I^T & -1 & 0  \\
%     l_{JC} \, \vec n_J^T & 0 & -1\\
%     l_{KC} \, \vec n_K^T & 0 & 0
%   \end{bmatrix}
% \end{equation}
% We need to add something extra to make this a non-singular matrix. One
% could for instance assume $\phi_I = \phi_J$.

% \subsection{Parametric Surface or Kernel Approach}
% \label{sec:param-surf-or}
% Assume we are handling triangle $C$ then we may be given some basis
% (kernel) function associated with the $I$ cell node
% \begin{equation}
%   W_I(  x, y, x_I, y_I)
% \end{equation}
% and similar for the other cell nodes. Now a parametric
% surface/interpolating function may be defined based on these given
% basis functions
% \begin{equation}
%   \phi(x,y) = \sum_{M \in \{I,J,K,C\}} W_M(x,y,x_M,y_M) \phi_M
% \end{equation}
% Obviously the second order von Neumann boundary condition on edge $I$ implies
% \begin{equation}
%   0 = \vec n_I^T \nabla^2 \phi(x_I, y_I) \vec n_I 
% \end{equation}
% which by definition of the parametric surface means
% \begin{equation}
%   0 =  \sum_{M \in
%     \{I,J,K,C\}} \underbrace{\vec n_I^T \nabla^2 W_M(x_I,y_I,x_M,y_M)
%     \vec n_I}_{d_M} \phi_M
% \end{equation}
% From which we conclude that we have found
% \begin{align}
%   \mat B_{II} &= -1\\
%   \mat B_{IJ} &=  \frac{d_J}{d_I}  \\
%   \mat B_{IK} &= \frac{d_K}{d_I} \\
%   \mat B_{IC} &= \frac{d_C}{d_I} \\
%   \vec c_I &= 0 
% \end{align}
% As before having more than one boundary edge makes the problem
% ill-posed and an extra condition must be added like $\phi_I = \phi_J$
% if $J$ is a boundary edge too. This yields
% \begin{align}
%   \mat B_{II} &= -1\\
%   \mat B_{IJ} &=  -1  \\
%   \mat B_{IK} &= \frac{d_K}{d_I - d_J} \\
%   \mat B_{IC} &= \frac{d_C}{d_I - d_J} \\
%   \vec c_I &= 0 
% \end{align}


\end{document}
